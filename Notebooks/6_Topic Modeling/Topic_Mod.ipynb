{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/mlreview/topic-modeling-with-scikit-learn-e80d33668730"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Datensaetze/news_POS_POS_tags_nouns_adjectives_verb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>filename</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>number_of_tokens</th>\n",
       "      <th>number_of_types</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>POS_tags</th>\n",
       "      <th>POS</th>\n",
       "      <th>nouns</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>verb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>business</td>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>Quarterly profits at US media giant TimeWarne...</td>\n",
       "      <td>415.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>quarterli profit at US media giant timewarn j...</td>\n",
       "      <td>['_SP', 'NNP', 'NNS', 'IN', 'NNP', 'NNS', 'NN'...</td>\n",
       "      <td>high fourth own fourth underlying exceptional ...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>002.txt</td>\n",
       "      <td>Dollar gains on Greenspan speech</td>\n",
       "      <td>The dollar has hit its highest level against ...</td>\n",
       "      <td>379.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>the dollar ha hit it highest level against th...</td>\n",
       "      <td>['_SP', 'DT', 'NN', 'VBZ', 'VBN', 'PRP$', 'JJS...</td>\n",
       "      <td>late recent sanguine current current next shar...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category filename                              title  \\\n",
       "0  business  001.txt  Ad sales boost Time Warner profit   \n",
       "1  business  002.txt   Dollar gains on Greenspan speech   \n",
       "\n",
       "                                             content  number_of_tokens  \\\n",
       "0   Quarterly profits at US media giant TimeWarne...             415.0   \n",
       "1   The dollar has hit its highest level against ...             379.0   \n",
       "\n",
       "   number_of_types                                       stemmed_text  \\\n",
       "0            244.0   quarterli profit at US media giant timewarn j...   \n",
       "1            230.0   the dollar ha hit it highest level against th...   \n",
       "\n",
       "                                            POS_tags  \\\n",
       "0  ['_SP', 'NNP', 'NNS', 'IN', 'NNP', 'NNS', 'NN'...   \n",
       "1  ['_SP', 'DT', 'NN', 'VBZ', 'VBN', 'PRP$', 'JJS...   \n",
       "\n",
       "                                                 POS  nouns  adjectives  verb  \n",
       "0  high fourth own fourth underlying exceptional ...   74.0        22.0   1.0  \n",
       "1  late recent sanguine current current next shar...   66.0        30.0   9.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Quarterly profits at US media giant TimeWarne...\n",
       "1        The dollar has hit its highest level against ...\n",
       "2        The owners of embattled Russian oil giant Yuk...\n",
       "3        British Airways has blamed high fuel prices f...\n",
       "4        Shares in UK drinks and food firm Allied Dome...\n",
       "                              ...                        \n",
       "2220     BT is introducing two initiatives to help bea...\n",
       "2221     Computer users across the world continue to i...\n",
       "2222     A new European directive could put software w...\n",
       "2223     The man making sure US computer networks are ...\n",
       "2224     Online role playing games are time-consuming,...\n",
       "Name: content, Length: 2225, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_features = 1000\n",
    "no_topics = 20\n",
    "n_components = 10\n",
    "n_top_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words=stop_words)\n",
    "tfidf = tfidf_vectorizer.fit_transform(documents)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words=stop_words)\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=no_topics, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: said government would people mr law police could lord home told public new bill secretary plans 000 also work uk\n",
      "Topic #1: mr brown blair prime minister chancellor labour election tony told gordon said book campaign claims iraq budget leader former role\n",
      "Topic #2: half minutes ball goal try game side second shot lead ireland first time back break victory minute italy win line\n",
      "Topic #3: film best award awards actor actress films festival oscar director star movie comedy nominated hollywood prize role stars nominations ceremony\n",
      "Topic #4: digital tv music technology broadband people show content video media bt devices million high online technologies service apple net dvd\n",
      "Topic #5: company shares firm market us stock deal said financial chief offer exchange executive euros business bid share group companies firms\n",
      "Topic #6: england wales ireland rugby france nations robinson coach six scotland squad injury team side captain players italy game saturday williams\n",
      "Topic #7: club chelsea league united arsenal liverpool cup season manchester manager champions football boss premiership players play team player side madrid\n",
      "Topic #8: band music album rock best chart number song singer awards single top pop record songs one artists us tour show\n",
      "Topic #9: open australian match win final beat round roddick set first play second champion top number cup year injury last said\n",
      "Topic #10: software users microsoft virus security search computer programs windows mail net program spam information internet google site web sites people\n",
      "Topic #11: yukos oil russian russia court tax unit sale state us company energy firm production protection legal bought giant sold authorities\n",
      "Topic #12: mobile phone phones mobiles use technology people services service using networks customers data messages calls network users used access call\n",
      "Topic #13: labour party election howard tax tory tories lib kennedy would campaign liberal taxes leader conservatives michael conservative voters parties general\n",
      "Topic #14: economy growth economic bank prices rate rates year dollar rise spending quarter 2004 figures us oil interest said consumer china\n",
      "Topic #15: games game gaming video titles sony play players like released playing time online microsoft computer release title pc sale industry\n",
      "Topic #16: eu european china countries europe us commission uk trade foreign union member states ministers talks law world aid germany rights\n",
      "Topic #17: olympic race champion world women record european year men cross best title madrid britain training season johnson old mark time\n",
      "Topic #18: ukip kilroy silk party mr robert leader meeting election said members east spokesman stand host london uk parties european british\n",
      "Topic #19: sales 2004 profits year rose december car christmas profit euros figures 2005 rise said 2003 strong last million quarter fell\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_top_words = 10\n",
    "display_topics(nmf, tfidf_feature_names, no_top_words)\n",
    "#display_topics(lda, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: year new us said million one 000 last first sales number also uk top sold industry people music market 2004\n",
      "Topic #1: software security microsoft virus mail users windows computer programs anti program attacks system pcs said people new information computers messages\n",
      "Topic #2: chelsea ukip party kilroy silk card mr said robert europe european leader cards uk parties one election last new host\n",
      "Topic #3: dvd high ray video films film sony home next games box technology entertainment mean standard current hollywood future quality players\n",
      "Topic #4: roddick festival davis iraq american film war films february year life michael including man career also open winner days include\n",
      "Topic #5: film best award awards actor also director star actress year prize oscar show films said comedy british role nominated ceremony\n",
      "Topic #6: said year economy growth us economic prices figures rise 2004 rate oil market last rates spending jobs months bank december\n",
      "Topic #7: said mr would government people could one public also new money get minister says want local make plans much many\n",
      "Topic #8: france said year bank italy profits market euros sales 2004 ireland stock growth shares nations us world however uk 2005\n",
      "Topic #9: mr said labour election blair would party brown people howard minister tory chancellor prime tories campaign government told leader britain\n",
      "Topic #10: calls bt call customers numbers rate broadband phone line companies says information rules signed last million number training get account\n",
      "Topic #11: said world new european year also would eu british uk london ms says people years us could make two countries\n",
      "Topic #12: said us court law legal mr rights would case government bill yukos state could trial foreign evidence russian company told\n",
      "Topic #13: rugby chart download spend uk official digital james nations spokesman becoming brown information 20 date gordon rights later next fans\n",
      "Topic #14: music band album song radio songs best rock number one record singer artists pop years really single chart black top\n",
      "Topic #15: game said time first one games england two play back win year last players world team would side good half\n",
      "Topic #16: commons martin mps use used devices mp members order long house campbell computers either nominated rules using michael political mr\n",
      "Topic #17: people mobile said technology phone use digital net phones services video service data using online used also broadband could users\n",
      "Topic #18: tv lord film new programmes project network software like file said films movie television screen one computer series bbc book\n",
      "Topic #19: said company mr firm search us site deal information also internet news google would companies web users one financial shares\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda.fit(tf)\n",
    "\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "display_topics(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/derekgreene/topic-model-tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 2225 raw text documents\n"
     ]
    }
   ],
   "source": [
    "raw_documents = df['content'].to_list()\n",
    "print(\"Read %d raw text documents\" % len(raw_documents)) #Laden der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_documents.append('mr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_documents.append('blair')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_documents.append('howard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document-Term Matrix erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopword list has 179 entries\n"
     ]
    }
   ],
   "source": [
    "#custom_stop_words = stopwords\n",
    "#with open( \"stopwords.txt\", \"r\", encoding=\"utf8\" ) as fin:\n",
    "    #for line in fin.readlines():\n",
    "        #custom_stop_words.append( line.strip() )\n",
    "# zur Kenntnis nehmen, dass wir es hashable machen müssen\n",
    "print(\"Stopword list has %d entries\" % len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 2225 X 29134 document-term matrix\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Verwendung einer benutzerdefinierten Stoppwortliste, setzen der Mindesthäufigkeit \n",
    "#von Term-Dokumenten auf 20\n",
    "vectorizer = CountVectorizer(stop_words = stop_words, min_df = 1)\n",
    "A = vectorizer.fit_transform(raw_documents)\n",
    "print( \"Created %d X %d document-term matrix\" % (A.shape[0], A.shape[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2225x29134 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 348409 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vokabular für das Korpus aufbauen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary has 29134 distinct terms\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "print(\"Vocabulary has %d distinct terms\" % len(terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['articles-raw.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dokument-Begriffsmatrix, Begriffe und Schnipsel zur späteren Verwendung speichern, indem wir Joblib verwenden, \n",
    "#um die Daten zu persistieren.\n",
    "\n",
    "import joblib\n",
    "snippets = []\n",
    "joblib.dump((A,terms,snippets), \"articles-raw.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term-Gewichtung mit TF-IDF anwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 2225 X 29134 TF-IDF-normalized document-term matrix\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# können die gleichen Vorverarbeitungsparameter übergeben\n",
    "vectorizer = TfidfVectorizer(stop_words = stop_words, min_df = 1)\n",
    "A = vectorizer.fit_transform(raw_documents)\n",
    "print( \"Created %d X %d TF-IDF-normalized document-term matrix\" % (A.shape[0], A.shape[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2225x29134 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 348409 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary has 29134 distinct terms\n"
     ]
    }
   ],
   "source": [
    "# den sich ergebenden Wortschatz extrahieren\n",
    "terms = vectorizer.get_feature_names()\n",
    "print(\"Vocabulary has %d distinct terms\" % len(terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "def rank_terms( A, terms ):\n",
    "    # die Summen über jede Spalte erhalten\n",
    "    sums = A.sum(axis=0)\n",
    "    # Gewichte den Begriffen zuordnen\n",
    "    weights = {}\n",
    "    for col, term in enumerate(terms):\n",
    "        weights[term] = sums[0,col]\n",
    "    # die Begriffe nach ihrem Gewicht über alle Dokumente einordnen\n",
    "    return sorted(weights.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01. said (86.10)\n",
      "02. mr (57.48)\n",
      "03. would (41.66)\n",
      "04. year (41.43)\n",
      "05. us (37.82)\n",
      "06. people (36.78)\n",
      "07. also (34.18)\n",
      "08. new (33.72)\n",
      "09. one (31.64)\n",
      "10. film (29.44)\n",
      "11. government (28.39)\n",
      "12. last (28.32)\n",
      "13. first (28.17)\n",
      "14. could (27.79)\n",
      "15. world (26.66)\n",
      "16. best (26.07)\n",
      "17. time (25.98)\n",
      "18. two (25.63)\n",
      "19. labour (25.42)\n",
      "20. uk (25.39)\n"
     ]
    }
   ],
   "source": [
    "#Rangliste der 20 wichtigsten Begriffe, was einen sehr groben Eindruck vom Inhalt der Dokumentensammlung vermittelt.\n",
    "\n",
    "ranking = rank_terms( A, terms )\n",
    "for i, pair in enumerate( ranking[0:20] ):\n",
    "    print( \"%02d. %s (%.2f)\" % ( i+1, pair[0], pair[1] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['articles-tfidf.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wieder Dokument-Begriffsmatrix, Begriffe und Schnipsel für die spätere Themenmodellierung mit Joblib speichern.\n",
    "\n",
    "joblib.dump((A,terms,snippets), \"articles-tfidf.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF Themen-Modelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Themenmodellierung zielt darauf ab, die verborgene thematische Struktur in einem großen Korpus von Textdokumenten automatisch zu entdecken. Ein Ansatz für die Themenmodellierung ist die Anwendung von Methoden der Matrixfaktorisierung, wie z.B. die Nicht-negative Matrixfaktorisierung (NMF). In diesem Notebook wird NMF unter Verwendung der Scikit-Lernbibliothek in Python angewendet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anwendung von NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2225 X 29134 document-term matrix\n"
     ]
    }
   ],
   "source": [
    "#die TF-IDF normalisierte Dokument-Begriffsmatrix und die Liste der Begriffe laden, \n",
    "#die wir vorher mit Joblib gespeichert haben.\n",
    "\n",
    "import joblib\n",
    "(A,terms,snippets) = joblib.load( \"articles-tfidf.pkl\" )\n",
    "print( \"Loaded %d X %d document-term matrix\" % (A.shape[0], A.shape[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Der wichtigste Eingabeparameter für den NMF ist die Anzahl der zu generierenden Themen k.\n",
    "#Zunächst wird ein geschätzter Wert verwendet.\n",
    "\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein anderer Grund für die Wahl für den NMF dreht sich um die Initialisierung. Am häufigsten wird beim NMF eine zufällige Initialisierung verwendet, um die Werte in den Faktoren W und H zu füllen. Je nach dem verwendeten Zufallssaatgut können Sie unterschiedliche Ergebnisse auf demselben Datensatz erhalten. Stattdessen liefert die Verwendung der SVD-basierten Initialisierung zuverlässigere Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# das Modell erstellen\n",
    "from sklearn import decomposition\n",
    "model = decomposition.NMF( init=\"nndsvd\", n_components=k ) \n",
    "# das Modell anwenden und die beiden Faktormatrizen extrahieren\n",
    "W = model.fit_transform( A )\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Untersuchung der Ausgabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Der W-Faktor enthält die Gewichte der Dokumentenmitgliedschaft relativ zu jedem der k Themen. \n",
    "#Jede Zeile entspricht einem einzelnen Dokument, und jede Spalte entspricht einem Thema.\n",
    "\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.  , 0.  , 0.02, 0.09, 0.02, 0.  , 0.01, 0.  , 0.03])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rundung auf 2 Dezimalstellen für Anzeigezwecke\n",
    "W[0,:].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 29134)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Der H-Faktor enthält die Begriffsgewichte relativ zu jedem der k Themen. \n",
    "#In diesem Fall entspricht jede Zeile einem Thema, und jede Spalte entspricht \n",
    "#einem eindeutigen Begriff im Korpusvokabular.\n",
    "\n",
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49, 0.12, 0.01, 0.02, 0.  , 0.  , 0.21, 0.  , 0.02, 0.23])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Zum Beispiel sehen wir bei dem Begriff \"Mensch\", \n",
    "#dass er stark mit einem einzigen Thema verbunden ist. \n",
    "#Auch hier kann in einigen Fällen jeder Begriff mit mehreren Themen assoziiert werden.\n",
    "\n",
    "term_index = terms.index('people')\n",
    "#Rundung auf 2 Dezimalstellen für Anzeigezwecke\n",
    "H[:,term_index].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thema Deskriptoren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die ranghöchsten Begriffe aus dem H-Faktor für jedes Thema können uns einen Einblick in den Inhalt des jeweiligen Themas geben. Dies wird oft als Themendeskriptor bezeichnet. Im Folgenden wird eine Funktion definiert, die den Deskriptor für ein bestimmtes Thema extrahiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Erhalten für jedes Thema einen Deskriptor anhand der am höchsten bewerteten Begriffe \n",
    "#(z.B. Top 10).\n",
    "\n",
    "import numpy as np\n",
    "def get_descriptor( terms, H, topic_index, top ):\n",
    "    # die Werte umgekehrt sortieren, um die Indizes zu sortieren\n",
    "    top_indices = np.argsort( H[topic_index,:] )[::-1]\n",
    "    # Erhalt der Begriffe, die den Indizes mit dem höchsten Rang entsprechen\n",
    "    top_terms = []\n",
    "    for term_index in top_indices[0:top]:\n",
    "        top_terms.append( terms[term_index] )\n",
    "    return top_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 01: mobile, music, digital, phone, people, technology, phones, video, broadband, tv\n",
      "Topic 02: mr, labour, election, blair, brown, party, chancellor, tax, prime, howard\n",
      "Topic 03: england, wales, ireland, rugby, robinson, game, nations, france, six, half\n",
      "Topic 04: film, best, awards, award, actor, actress, oscar, festival, films, director\n",
      "Topic 05: growth, economy, economic, sales, year, bank, us, 2004, said, prices\n",
      "Topic 06: yukos, russian, oil, gazprom, yugansk, rosneft, russia, company, bankruptcy, court\n",
      "Topic 07: said, government, would, law, mr, eu, secretary, lord, lords, bill\n",
      "Topic 08: champion, open, world, olympic, seed, final, win, australian, year, set\n",
      "Topic 09: chelsea, club, liverpool, league, united, arsenal, game, mourinho, champions, gerrard\n",
      "Topic 10: software, microsoft, users, virus, search, security, spyware, mail, programs, windows\n"
     ]
    }
   ],
   "source": [
    "descriptors = []\n",
    "for topic_index in range(k):\n",
    "    descriptors.append( get_descriptor( terms, H, topic_index, 10 ) )\n",
    "    str_descriptor = \", \".join( descriptors[topic_index] )\n",
    "    print(\"Topic %02d: %s\" % ( topic_index+1, str_descriptor ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die obigen Ranglisten zeigen nicht die Stärke der Assoziation für die verschiedenen Kategorien. Wir können die Verteilung der Gewichte für die Top-Terme in einem Genre mit einem horizontalen Balkendiagramm der Matplotlib darstellen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "matplotlib.rcParams.update({\"font.size\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definieren einer Funktion zum Erstellen eines Balkendiagramms für die angegebenen Daten, \n",
    "#basierend auf dem H-Faktor aus dem aktuellen NMF-Modell.\n",
    "\n",
    "def plot_top_term_weights( terms, H, topic_index, top ):\n",
    "    # die Top-Begriffe und ihre Gewichtung erhalten\n",
    "    top_indices = np.argsort( H[topic_index,:] )[::-1]\n",
    "    top_terms = []\n",
    "    top_weights = []\n",
    "    for term_index in top_indices[0:top]:\n",
    "        top_terms.append( terms[term_index] )\n",
    "        top_weights.append( H[topic_index,term_index] )\n",
    "    # beachten Sie, dass wir die Reihenfolge der Handlung umkehren\n",
    "    top_terms.reverse()\n",
    "    top_weights.reverse()\n",
    "    # erstellen des Plots\n",
    "    fig = plt.figure(figsize=(13,8))\n",
    "    # das horizontale Balkendiagramm hinzufügen\n",
    "    ypos = np.arange(top)\n",
    "    ax = plt.barh(ypos, top_weights, align=\"center\", color=\"green\",tick_label=top_terms)\n",
    "    plt.xlabel(\"Term Weight\",fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So können wir z.B. für das 7. Thema ein Diagramm mit den 15 wichtigsten Begriffen erstellen:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_top_term_weights( terms, H, 6, 15 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['articles-model-nmf-k10.pkl']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wenn dieses Themenmodell für spätere Benutzer behalten werden soll, \n",
    "# kann man es mit Hilfe der joblib speichern.\n",
    "\n",
    "joblib.dump((W,H,terms,snippets), \"articles-model-nmf-k%02d.pkl\" % k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameterauswahl für NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun soll die fortgeschrittenere Aufgabe der Parameterauswahl für die NMF-Themenmodellierung betrachtet werden - nämlich die Auswahl eines nützlichen Wertes für die Anzahl der Themen k.\n",
    "\n",
    "Zuerst wird die TF-IDF normalisierte Dokument-Begriffsmatrix und die Liste der Begriffe, die wir zuvor mit Joblib gespeichert haben geladen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erstellen der Themenmodelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein üblicher Ansatz für die Parameterauswahl besteht darin, die Themenkohärenz von Modellen zu messen und zu vergleichen, die für verschiedene Werte von k generiert wurden.\n",
    "\n",
    "Man beginnt damit, einen anfänglichen Bereich \"sinnvoller\" Werte vorzugeben.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmin, kmax = 4, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying NMF for k=4 ...\n",
      "Applying NMF for k=5 ...\n",
      "Applying NMF for k=6 ...\n",
      "Applying NMF for k=7 ...\n",
      "Applying NMF for k=8 ...\n",
      "Applying NMF for k=9 ...\n",
      "Applying NMF for k=10 ...\n",
      "Applying NMF for k=11 ...\n",
      "Applying NMF for k=12 ...\n",
      "Applying NMF for k=13 ...\n",
      "Applying NMF for k=14 ...\n",
      "Applying NMF for k=15 ...\n"
     ]
    }
   ],
   "source": [
    "#Anwenden des NMFs für jeden dieser Werte.\n",
    "\n",
    "from sklearn import decomposition\n",
    "topic_models = []\n",
    "# try each value of k\n",
    "for k in range(kmin,kmax+1):\n",
    "    print(\"Applying NMF for k=%d ...\" % k )\n",
    "    # run NMF\n",
    "    model = decomposition.NMF( init=\"nndsvd\", n_components=k ) \n",
    "    W = model.fit_transform( A )\n",
    "    H = model.components_    \n",
    "    # store for later\n",
    "    topic_models.append( (k,W,H) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erstellen des Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Anzahl der Themen auszuwählen, wird hier ein Themenkohärenzmaß namens TC-W2V verwendet. Dieses Maß beruht auf der Verwendung eines Worteinbettungsmodells, das aus dem entsprechenden Korpus konstruiert wurde. In diesem Schritt wird also die Gensim-Implementierung von Word2Vec verwendet, um auf der Grundlage unserer Sammlung von Songtexten ein Word2Vec-Modell zu erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 2225 raw text documents\n"
     ]
    }
   ],
   "source": [
    "#raw_documents = df['text'].to_list()\n",
    "print(\"Read %d raw text documents\" % len(raw_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopword list has 179 entries\n"
     ]
    }
   ],
   "source": [
    "#Einlesen der Stopwortliste.\n",
    "\n",
    "#custom_stop_words = []\n",
    "#with open( \"stopwords.txt\", \"r\", encoding = \"utf8\" ) as fin:\n",
    "    #for line in fin.readlines():\n",
    "        #custom_stop_words.append( line.strip().lower() )\n",
    "# note that we need to make it hashable\n",
    "print(\"Stopword list has %d entries\" % len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zunächst muss man eine Klasse definieren, die Dokumente in einer Form erzeugt, \n",
    "#die von der Word2Vec-Implementierung von Gensim verwendet werden kann.\n",
    "\n",
    "import re\n",
    "class TokenGenerator:\n",
    "    def __init__( self, raw_documents, stop_words ):\n",
    "        self.documents = raw_documents\n",
    "        self.stopwords = stop_words\n",
    "        self.tokenizer = re.compile( r\"(?u)\\b\\w\\w+\\b\" )\n",
    "\n",
    "    def __iter__( self ):\n",
    "        print(\"Building Word2Vec model ...\")\n",
    "        for doc in self.documents:\n",
    "            tokens = []\n",
    "            for tok in self.tokenizer.findall( doc ):\n",
    "                if tok in self.stopwords:\n",
    "                    tokens.append( \"<stopword>\" )\n",
    "                elif len(tok) >= 2:\n",
    "                    tokens.append( tok )\n",
    "            yield tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Word2Vec model ...\n",
      "Building Word2Vec model ...\n",
      "Building Word2Vec model ...\n",
      "Building Word2Vec model ...\n",
      "Building Word2Vec model ...\n",
      "Building Word2Vec model ...\n"
     ]
    }
   ],
   "source": [
    "#Erstellen mit Gensim ein Skipgram Word2Vec-Modell aus allen Dokumenten in der Eingabedatei.\n",
    "\n",
    "import gensim\n",
    "docgen = TokenGenerator( raw_documents, stop_words)\n",
    "# das Modell hat 500 Dimensionen, die minimale Dokument-Begriffshäufigkeit beträgt 20\n",
    "w2v_model = gensim.models.Word2Vec(docgen, min_count=1, size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 33184 terms\n"
     ]
    }
   ],
   "source": [
    "print(\"Model has %d terms\" % len(w2v_model.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Erstelltes Model abspeichern.\n",
    "\n",
    "w2v_model.save(\"w2v-model.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "# Laden des Modells, das wir zuvor erstellt haben.\n",
    "W = topic_models[k-kmin][1]\n",
    "H = topic_models[k-kmin][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 01: mobile, people, music, said, digital, technology, phone, users, broadband, software\n",
      "Topic 02: mr, labour, election, blair, party, brown, said, would, government, howard\n",
      "Topic 03: england, game, win, wales, ireland, said, team, play, cup, first\n",
      "Topic 04: film, best, awards, award, actor, actress, oscar, festival, films, director\n",
      "Topic 05: growth, economy, said, us, year, bank, economic, sales, oil, prices\n"
     ]
    }
   ],
   "source": [
    "#Anzeigen der Themendeskriptoren für dieses Modell.\n",
    "\n",
    "for topic_index in range(k):\n",
    "    descriptor = get_descriptor( terms, H, topic_index, 10 )\n",
    "    str_descriptor = \", \".join( descriptor )\n",
    "    print(\"Topic %02d: %s\" % ( topic_index+1, str_descriptor ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
